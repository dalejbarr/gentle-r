---
title: "Multiple Regression Formative Exercise"
author: "L3 Teaching Team"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Background

For this set of formative exercises, you're going to be working with some real data collected about students from a previous year of students in statistics at the University of Glasgow. The data have been anonymized, and includes no demographic or other sensitive information. Each student is identified by a unique value of the variable `id`.

Students were given the STats Anxiety Rating Scale (STARS), a 51-item questionnaire which measures student's attitudes toward statistics (Cruise, Cash, & Bolton, 1985).  In each item, students are asked to rate either agreement with a statement on a 1 to 5 scale (1 = strongly disagree, 5 = strongly agree), or rate how anxious they would feel on a 1 to 5 scale (1 = no anxiety, 5 = strong anxiety). Higher numbers mean more anxiety or more negative attitudes toward statistics.  

There are some additional files that you'll need to download in order to do the task.

If you're interested, you can see the individual survey items in the accompanying file `stars-items.pdf`. 

The rating data is in the file `stars.csv`. 

The STARS items can be divided up into six different subscales (Hanna, Shevlin, & Dempster, 2008). The subscales and the mapping of items to subscales is given in the file `subscales.csv`.

Students in this course were allowed to freely choose what software they used to perform the class assignments, either SPSS or R. The file `software.csv` has information about which software each student chose.

Your task is to use multiple regression examine the relationship between the stats anxiety subscales and overall performance in the class, as measured by the students' final grades, which are in the file `grades.csv`.

# Tasks

Write solution code in the chunks provided for each task.

## Task 1: Import the data

You will need to use the **`tidyverse`** package as well as the **`corrr`** package. Load in those packages as well as `stars.csv`, `grades.csv`, `software.csv`, and `subscales.csv`. You might want to look at the [Data Import Cheat Sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf){target="_blank"}.

```{r data-import, message = FALSE}
library("corrr")
library("tidyverse")

stars <- read_csv("stars.csv",
                  col_types = cols(.default = col_integer()))

grades <- read_csv("grades.csv", col_types = "ii")

software <- read_csv("software.csv", col_types = "ic")

subscales <- read_csv("subscales.csv", col_types = "cc")
```


## Task 2: Calculate subscale means

Calculate the mean score for each subscale for each student.

```{r subscale-means}
## what should the final table look like?
## id   subscale       mean_score
##  3   Ask_For_Help   2.2
##  3   Interpretation 1.7 ... etc

stars_long <- stars |>
  pivot_longer(-id, names_to = "item_id",
               values_to = "score")

subscale_means <- stars_long |>
  inner_join(subscales,
             join_by(item_id)) |>
  group_by(id, subscale) |>
  summarise(mean_score = mean(score, na.rm = TRUE),
            .groups = "drop")
```


## Task 3: Create a correlation matrix

Create a correlation matrix using `corrr::correlate()` showing the bivariate correlation between your response variable (`grade`) and the six subscale means.

```{r corr-mx}
## pivot back to wide, and then join grades
## resulting table should look like so:
## id Ask_For_Help Interpretation Self_Concept Teacher Test Worth grade
##  3            1              1            1       1 1.25 1.06   ???
##

subscale_wide <- subscale_means |>
  pivot_wider(names_from = "subscale",
              values_from = "mean_score") |>
  inner_join(grades, join_by(id)) |>
  select(-id)

subscale_wide |>
  correlate() |>
  shave() |>
  fashion() |>
  knitr::kable()

## lost two rows in the join!
## i.e., two students for whom we lack grades
```


## Task 4: Visualize all pairwise correlations

Now visualize all of the pairwise correlations.

```{r pairs, fig.width = 6, fig.height = 6}
subscale_wide |>
  pairs()
```


## Task 5: Run the multiple regression

Estimate the parameters for the multiple regression, with grade as the response variable and the subscale means as the predictors. This should be straightforward if your data are in the right format. Don't forget to display your results using `summary()`, and take a moment to think about what all the numbers mean.

```{r fit-model}
mod <- lm(grade ~ Ask_For_Help + Interpretation + Self_Concept +
            Teacher + Test + Worth, subscale_wide)

summary(mod)
```


## Task 6: Which subscale is the 'best' predictor?

Is there one subscale that is more strongly linked to the final grade? The different subscales have different variances, so you need to re-run the regression after standardizing the variables.

```{r best-predictor}
subscale_c <- subscale_wide |>
  mutate(afh_c = (Ask_For_Help - mean(Ask_For_Help)) / sd(Ask_For_Help),
         int_c = (Interpretation - mean(Interpretation)) / sd(Interpretation),
         sc_c = (Self_Concept - mean(Self_Concept)) / sd(Self_Concept),
         teacher_c = (Teacher - mean(Teacher)) / sd(Teacher),
         test_c = (Test - mean(Test)) / sd(Test),
         worth_c = (Worth - mean(Worth)) / sd(Worth))

mod_c <- lm(grade ~ afh_c + int_c + sc_c + teacher_c +
              test_c + worth_c, subscale_c)

summary(mod_c)
```


## Task 7: Compare models

Could we do just as well predicting grades from the 'best' predictor as we could by including all six subscale predictors? Do an analysis to test this.

```{r compare-models}
## NB: you can use the standardized model if you wish

mod_sconly <- lm(grade ~ Self_Concept, data = subscale_wide)

anova(mod_sconly, mod)

## no evidence that the other subscales are predicting grade
## beyond self-concept!
```


## Task 8: Choice of software and grade

Run a simple regression that predicts grades by choice of software (SPSS versus R).

```{r grade-by-software}
software_d <- software |>
  mutate(software_d = if_else(software == "SPSS", 0L, 1L))

## double check
software_d |>
  distinct(software, software_d)

softgrade <- grades |>
  inner_join(software_d, join_by(id == ID))

softgrade |>
  group_by(software) |>
  summarise(mean_grade = mean(grade, na.rm = TRUE),
            .groups = "drop")

mod_soft <- lm(grade ~ software_d, data = softgrade)

summary(mod_soft)

mod_soft2 <- lm(grade ~ software, data = softgrade)

summary(mod_soft2)
```

## Extra Task (optional): Visualize the subscale means

Use ggplot to create an informative graph of the subscale means.

```{r subscale-plot}
sub_means <- subscale_means %>%
  group_by(subscale) %>%
  summarise(mean_score = mean(mean_score),
            .groups = "drop")

ss_levels <- sub_means %>% pull(subscale)

ggplot(subscale_means, aes(subscale, mean_score, colour = subscale)) +
  geom_violin(aes(fill = subscale), alpha = .2) +
  geom_jitter(alpha = .2) +
  geom_point(data = sub_means, size = 3) +
  theme(legend.position = "none") +
  scale_x_discrete(limits = rev(ss_levels)) +
  coord_flip(ylim = c(1, 5))
```


# References

Cruise, R. J., Cash, R. W., & Bolton, D. L. (1985). Development and validation of an  instrument to measure statistical anxiety. *Paper presented at the proceedings of the American Statistical Association.*

Hanna, D., Shevlin, M., & Dempster, M. (2008). The structure of the statistics anxiety rating scale: A confirmatory factor analysis using UK psychology students. *Personality and Individual Differences*, *45*, 68-74.
